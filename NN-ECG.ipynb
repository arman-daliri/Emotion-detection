{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-0ifqW2a8mU",
    "outputId": "199ad2a9-a6fb-4b03-f160-0b9f4bae044a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: colorama\n",
      "Successfully installed colorama-0.4.6\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting smote_variants\n",
      "  Downloading smote_variants-0.7.1-py3-none-any.whl (407 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.4/407.4 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from smote_variants) (2.11.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from smote_variants) (1.2.2)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.9/dist-packages (from smote_variants) (2.11.0)\n",
      "Collecting statistics\n",
      "  Downloading statistics-1.0.3.5.tar.gz (8.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting metric-learn\n",
      "  Downloading metric_learn-0.6.2-py2.py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.9/dist-packages (from smote_variants) (1.22.4)\n",
      "Requirement already satisfied: seaborn in /usr/local/lib/python3.9/dist-packages (from smote_variants) (0.12.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from smote_variants) (1.4.4)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.9/dist-packages (from smote_variants) (2019.0)\n",
      "Collecting minisom\n",
      "  Downloading MiniSom-2.3.1.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from smote_variants) (1.1.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from smote_variants) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->smote_variants) (3.1.0)\n",
      "Requirement already satisfied: intel-openmp in /usr/local/lib/python3.9/dist-packages (from mkl->smote_variants) (2023.0.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->smote_variants) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->smote_variants) (2.8.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.9/dist-packages (from seaborn->smote_variants) (3.7.1)\n",
      "Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.9/dist-packages (from statistics->smote_variants) (0.16)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (0.31.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (0.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (1.15.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (3.8.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (1.51.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (23.3.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (63.4.3)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (1.6.3)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (2.11.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (1.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (4.5.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (3.19.6)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (2.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (15.0.6.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->smote_variants) (2.11.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->smote_variants) (0.40.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->smote_variants) (5.12.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->smote_variants) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->smote_variants) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->smote_variants) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->smote_variants) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->smote_variants) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn->smote_variants) (4.39.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->smote_variants) (2.16.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->smote_variants) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->smote_variants) (2.2.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->smote_variants) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->smote_variants) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->smote_variants) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->smote_variants) (2.27.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (5.3.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (1.3.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn->smote_variants) (3.15.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (6.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (1.26.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->smote_variants) (3.2.2)\n",
      "Building wheels for collected packages: minisom, statistics\n",
      "  Building wheel for minisom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for minisom: filename=MiniSom-2.3.1-py3-none-any.whl size=10609 sha256=6a5184d3511d93d348215f8b51e880b7e5fc68fa5c80f64855c79a09c634e318\n",
      "  Stored in directory: /root/.cache/pip/wheels/b4/aa/7a/d9a88098f7877aa95dd4f227fe614f75773654baa39b47bba6\n",
      "  Building wheel for statistics (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for statistics: filename=statistics-1.0.3.5-py3-none-any.whl size=7453 sha256=13b4a7f793f6add4b6dab12f1fedffc8bd50e3d741e7070d42872991d94d5afe\n",
      "  Stored in directory: /root/.cache/pip/wheels/26/3c/70/9467407f3aa90862061eadcd286627b23a8bab6789b667776f\n",
      "Successfully built minisom statistics\n",
      "Installing collected packages: minisom, statistics, metric-learn, smote_variants\n",
      "Successfully installed metric-learn-0.6.2 minisom-2.3.1 smote_variants-0.7.1 statistics-1.0.3.5\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting imbalanced_databases\n",
      "  Downloading imbalanced_databases-0.1.1-py3-none-any.whl (4.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from imbalanced_databases) (1.4.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from imbalanced_databases) (1.22.4)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from imbalanced_databases) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->imbalanced_databases) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->imbalanced_databases) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->imbalanced_databases) (1.15.0)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2955 sha256=909540c2324c2994b2d5331a4ada6fc393b7073c25b12ce6fb05816e33efbde9\n",
      "  Stored in directory: /root/.cache/pip/wheels/f8/e0/3d/9d0c2020c44a519b9f02ab4fa6d2a4a996c98d79ab2f569fa1\n",
      "Successfully built sklearn\n",
      "Installing collected packages: sklearn, imbalanced_databases\n",
      "Successfully installed imbalanced_databases-0.1.1 sklearn-0.0.post1\n"
     ]
    }
   ],
   "source": [
    "# preprocessing of google colaboratory\n",
    "!pip install colorama\n",
    "!pip install smote_variants\n",
    "!pip install imbalanced_databases "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fbIgSDqRlFwi"
   },
   "outputs": [],
   "source": [
    "# Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "xwQbFvQ_dUVc"
   },
   "outputs": [],
   "source": [
    "# initial and general libraries\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from colorama import Fore, Back, Style\n",
    "from sklearn import tree\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import itertools\n",
    "from matplotlib import pyplot\n",
    "import xgboost\n",
    "from sklearn.datasets import make_regression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter,\n",
    "                               AutoMinorLocator)\n",
    "\n",
    "# machine learning libraries\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "\n",
    "\n",
    "# preprocessing libraries\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# accuracy and metrics libraries\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# improve hyperparameters libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# fill null data libraries\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Balancing dataset\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#imbalaced dataset \n",
    "import smote_variants as sv\n",
    "import imbalanced_databases as imbd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "\n",
    "# call algorithms ( classifiers)\n",
    "#  Random Forest Classifier\n",
    "RfcModel = RandomForestClassifier()\n",
    "# call Decision Tree Algorithm\n",
    "DTModel = DecisionTreeClassifier()\n",
    "# Call Logistic Regression model algorithm\n",
    "LRModel = LogisticRegression()\n",
    "# call support vector machine\n",
    "svcModel = SVC()\n",
    "# call Random forest Regressor\n",
    "rfrModel = RandomForestRegressor()\n",
    "# call GaussianNB\n",
    "nbModel = GaussianNB()\n",
    "# call QuadraticDiscriminantAnalysis\n",
    "qdaModel = QuadraticDiscriminantAnalysis() \n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "# NN Librarys\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "GFYLDSQNeGMJ",
    "outputId": "8ebaee7c-c339-4233-bce4-8e7e493f4b21"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-426dc855-455a-48fa-8e49-d42ef2d4a217\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videos</th>\n",
       "      <th>subjects1</th>\n",
       "      <th>subjects2</th>\n",
       "      <th>subjects3</th>\n",
       "      <th>subjects4</th>\n",
       "      <th>subjects5</th>\n",
       "      <th>subjects6</th>\n",
       "      <th>subjects7</th>\n",
       "      <th>subjects8</th>\n",
       "      <th>subjects9</th>\n",
       "      <th>...</th>\n",
       "      <th>subjects55</th>\n",
       "      <th>subjects56</th>\n",
       "      <th>subjects57</th>\n",
       "      <th>subjects58</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 65 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-426dc855-455a-48fa-8e49-d42ef2d4a217')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-426dc855-455a-48fa-8e49-d42ef2d4a217 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-426dc855-455a-48fa-8e49-d42ef2d4a217');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   videos  subjects1  subjects2  subjects3  subjects4  subjects5  subjects6  \\\n",
       "0       1          1          3          3          1          2          1   \n",
       "1       2          1          1          1          1          1          1   \n",
       "2       3          1          1          2          1          1          1   \n",
       "3       4          1          1          1          1          1          1   \n",
       "4       5          1          3          2          1          1          1   \n",
       "\n",
       "   subjects7  subjects8  subjects9  ...  subjects55  subjects56  subjects57  \\\n",
       "0          3          5          2  ...           1           1           1   \n",
       "1          3          5          1  ...           2           1           1   \n",
       "2          1          2          2  ...           2           1           1   \n",
       "3          1          6          1  ...           1           1           1   \n",
       "4          3          4          1  ...           2           1           1   \n",
       "\n",
       "   subjects58  class1  class2  class3  class4  class5  class6  \n",
       "0           1      36      12       6       0       4       0  \n",
       "1           1      40       7       5       2       3       1  \n",
       "2           1      39      15       2       1       0       1  \n",
       "3           1      42       5       6       0       3       2  \n",
       "4           1      38       9       5       2       4       0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import dataset\n",
    "OrgData = pd.read_csv('drive/MyDrive/Project/ECG Data.csv')\n",
    "OrgData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_7X2CX-mjyg"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwQBVvayeN_Y",
    "outputId": "f126a6e1-930f-46e9-af13-d0123988102b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "videos       int64\n",
       "subjects1    int64\n",
       "subjects2    int64\n",
       "subjects3    int64\n",
       "subjects4    int64\n",
       "             ...  \n",
       "class2       int64\n",
       "class3       int64\n",
       "class4       int64\n",
       "class5       int64\n",
       "class6       int64\n",
       "Length: 65, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrgData.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ipkL0DpWenml",
    "outputId": "e6f60ce7-55b6-4efc-cbea-926fa31ba9e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-80c06542-7660-43de-90b2-24c2a82ec364\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>videos</th>\n",
       "      <td>36.0</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>10.535654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.75</td>\n",
       "      <td>18.5</td>\n",
       "      <td>27.25</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.876501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.694444</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.983999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.464621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.472708</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>5.027778</td>\n",
       "      <td>2.117763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.527778</td>\n",
       "      <td>1.206793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class5</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2.361111</td>\n",
       "      <td>1.073120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class6</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>1.478953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80c06542-7660-43de-90b2-24c2a82ec364')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-80c06542-7660-43de-90b2-24c2a82ec364 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-80c06542-7660-43de-90b2-24c2a82ec364');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           count       mean        std  min   25%   50%    75%   max\n",
       "videos      36.0  18.500000  10.535654  1.0  9.75  18.5  27.25  36.0\n",
       "subjects1   36.0   1.444444   0.876501  1.0  1.00   1.0   1.00   4.0\n",
       "subjects2   36.0   1.694444   1.166667  1.0  1.00   1.0   3.00   6.0\n",
       "subjects3   36.0   2.055556   0.983999  1.0  1.00   2.0   2.25   6.0\n",
       "subjects4   36.0   1.111111   0.464621  1.0  1.00   1.0   1.00   3.0\n",
       "...          ...        ...        ...  ...   ...   ...    ...   ...\n",
       "class2      36.0   7.000000   2.472708  3.0  5.00   6.0   8.00  15.0\n",
       "class3      36.0   5.027778   2.117763  0.0  3.00   5.0   6.25   9.0\n",
       "class4      36.0   1.527778   1.206793  0.0  1.00   1.0   2.00   4.0\n",
       "class5      36.0   2.361111   1.073120  0.0  2.00   2.0   3.00   4.0\n",
       "class6      36.0   1.388889   1.478953  0.0  0.00   1.0   2.00   5.0\n",
       "\n",
       "[65 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrgData.describe(include = 'all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N4bpj4B8evUc",
    "outputId": "2aac8a33-f4ed-4217-ee54-abd2dc1f5f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset have 36     instances(rows)\n",
      "dataset have 65   features(columns)\n"
     ]
    }
   ],
   "source": [
    "# row and column count\n",
    "rowCount = OrgData.shape[0]\n",
    "colCount = OrgData.shape[1]\n",
    "print('dataset have '+(str(rowCount))+'     instances(rows)')\n",
    "print(f'dataset have '+(str(colCount))+'  '+' features(columns)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VYv5550afFHV"
   },
   "outputs": [],
   "source": [
    "#### Null data bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "-KluAvK4ffn3",
    "outputId": "20a674f8-dfa1-44a5-ec0f-a15339d6a55a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 4))\n",
    "orgdataBar = OrgData.isnull().sum().plot(kind = 'bar', color = 'red')\n",
    "plt.xlabel('Features Name')\n",
    "plt.ylabel('NULL Count', fontsize = 20)\n",
    "plt.title('NULL data count', fontsize = 20,fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "by2XaKrugCMK"
   },
   "outputs": [],
   "source": [
    "#### dataset Features bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "H_PDguL5gFS6",
    "outputId": "377bad5c-0804-419f-bc4c-a09307d4c1c3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAFTCAYAAAAHuau+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABBuElEQVR4nO3deZwcVdX/8c8khDVhC2GVTaQOIDu4AiLPDxRERGVXdjcEwUcEUR+UoAiCyINsCiqroIALm4IsGtn3AAqPB0SWsCgxbAk7yfz+uLdJTad7uiqpmu7q+r5fr37NdPXpe0539cycrrl9a2BwcBARERERESnWqG4XICIiIiLSj9Roi4iIiIiUQI22iIiIiEgJ1GiLiIiIiJRAjbaIiIiISAnUaIuIiIiIlGC+bhcgItJLzGwSsHm8+hd3/2D3qhmemT0KrByvnuPue3evGhERaaZGW0R6npmtAjySJdbdB8qtJjszOxvYK159zN1X6V41nZnZB4E/pzZt4e6TulNN9bV43e7j7md3pxoR6QY12iIiQ/0YuCJ+P6WbhYiISLWp0RaRKroTuLCMgd29lHFFRKR+BnQKdhHpdS3+Bd9xPrKZ7Qv8PLXpo+7++3jbwsA9wOrxtpuBzd39zeHmaJuZAV8DPgC8DRgNTAOeIDT/v3b368xsb+CsDg/rSHef2CEGM1sA+DqwZ8z5NPAr4LvA/bSZo21mhwLvB9YCxgOLAa8SnsdrgRPc/YlUfKc/Bm9NfYnP7YeAdYAJwOLA64T/AFwPnOju/9fpsbV4rJsCn491Lxc3Pw3cDvzQ3e9KxQ4AuxKelw2BJYCXAQcuAU519xebxk8/xiHPv5lNBI5oXE9PQWp+TQC7ABOBjwFLAY8DZwDHu/tgvM+jzN43LfXSNCcRKYeOaItIX3L3M81sS2C3uOlnZra2u08DfsjsJvs5YDd3f3O48WKTfScwtummZeNlY2Ah4LqCHgJmNpowjWXL1OaVgcOALYAFh7n7YYQGO20soTleB9jbzDZ19wfmorT9gY2ato0B1oiXvcxs6zzzu83sRODLLW5aLV5uB+6KsQsBvwM+3BS7GPDuePmcmX3Y3R/KWkNGKwJ3A8untr0DOA5YGDiy4HwiUmFqtEWkit5pZoe02P43d78qdf0LhKZrNUIzfJqZnQXsl4rZ190fz5BzH2Y32c8Tjlj/B1gmjv+BVOwdwKGEI58bx23PAUenYm7OkPNLDG2yHwYuIjTQ+xCa23aeACYBj8Xcg4Qj4jsDSxKOAB8HfDTGHxofR/q5+UnMCfBCavtUwhuAf8Sx3yA8v58gNKILAKcAa2d4jJjZfzO0yX6ZMDXoUWAlYJumu5zA0Cb7FuAaICEc5QZYFbjUzNbt9CYqp7cT/jPwY+AV4IuEN1gAB5vZ0e7+BvA9YBXgm6n7Xkh4syYiNaFGW0SqaGNmN7Bp5wBvNdruPt3MdgVuAuYnNJkfScWf7O6XZMyZPnp8obsfnL7RzMYQj3K6+/3A/Wa2dqrOF939+Iy5GtJN7/PAu9392ZjvRuDcdnd09/XNbBzwPkLDtwihab4B2D6GbWlmY9z9DXc/Pq46ks55Yauj0u6+jZktCLyX0JyPI0wbuZbwBgDCm6EV3X3YD5Sa2SjC1JiGF4GN3P0fqZj5gaXj90sCn03FXw/8l7vPjLc/CHw73rYmsB3h6HeRdnX3S2O+x4ET4/ZFCUf0/+ruP41TntKN9lVadUSkXtRoi0hfc/c7zewbhOkiMPuo9GTCUdys/sLso65fMLN3A/9HOKp7L/And3+sgJIBMLOxhKat4fJGkx1dQJiDPsdR7di8HgUcTDi63M4ChDnGT+es7cvAdwiN5XDeRueVW4zwX4GGM9NNNoC7v044Qg/wHob+7Tq30WQ37s/sRhtgE4pttJ9qNNmN8ppuX6LAXCJScWq0RaSK8p6c5eeEubPp+dU/cffXsg7g7r8zs6OArxKmCmwQLw2vmtkh7n5qjrqGs3jT9X831TPTzKYRpmw0+xLwjYx5hmvE52BmH2P2Edwixl6y6Xqn9dKb4//V4XpzfEPzBxGzPg+PNl1vfg3pjMsi8hb9QhCROvgxc36I8Rgze1ueQdz9W4RVNrYEDiQ0nPfGmxcEfmRmb5+3Ut/yQtP19FHfxgclmz/s2LBr6vunCNNHFoyrXBwwj3Wlx36JMH964Tj2tnMx3rNN11fNGd/8RqP5ejo+verIQk1xq5PNG03XtXSXiLSlRltE+pqZfYbZK4+8CTRWoVgSuCA2rFnGWdXMlnD3l9z9Onc/xd2/AvxXKmw0Q49yp5uyhfPU7e7Tgb+nNn00zk9u+BTtPwy5VOr7u9z9Vnd/LU4p2WmYtM1NZKua02P/092vcvdX4vVdW8R34sAzqev7Nr9ZMbMxqTdFtxH2Y8Oe8XG9df+m8W9Kff986vt3xyUCMbN1CHO5i5bl+RSRPqapIyJSRe1WHYHwAb4pAGa2JnBS6rajCCs/3E04orkZYe3kbzcP0sIOhKPgNxCaw6cJ0w+2bopLH0F9IvX9hHhK9vsJR0HPc/ch00FaOIOwwgaEub+3m9mFhGZ3n7b3CvU1jtBua2Y/BZ4kHHFu9SHSVvUCfM/M1ieskT3Z3a+LY28Vb18n1vM34IMMfdORibvPMrNjgP+NmxYF7jOzXxFWTFme8Bz/iLA+97NmdiZhvW0Iq73caGbXxMecbvYduDx1/TZm76/NgVvN7CnCfyjmz1t7Bs8QnrvG2IeY2VKEVVUedveiP6QpIj1GjbaIVFG7VUcgLJ82Ja6KcSGzjyLeBnwvnpTmUMLycwD/Y2Z/yrjm83yE9au3aHP7TYRVMBp+C3yLcKQbYK/UbZNomnfdwsmE5fcaDexqzF7F4q+Ek7os1eJ+xxCWvxtD+M9lY5WON4FfALu3Subuj5nZHcC74qb14wXgVMIa4ScSThLT+CDkzvECYcnD4d4AtPMjwpSRg+L1RYDPDBP/FcIye42lD98XL2mPA9s3Le33A8KJdhpHwN8dv74M/Jn2+3WuuPsbZnYps/+LsCqz19n+PcWvhiIiPUZTR0SkX51AODELhLnEezSarviBxSvjbaOA8+ORxuFcRjj6fRVhmbwXgZmEI9g3E84YuVV6BQx3/yvhSPhthGYul1jvtoQVPh4hTEWYQjj6u1l8XK3udzOhCb2BsObzdOBPhKO4nU6o80nCG5SpwKwWYz8cc18Z878M3Eo4S2Lb5QaH4+6D7v5lwtHpXwD/jHW/SjiqfRFwYyr+ZcIbiT2AP8Za3yTskzuBw4H13H3IiiDu/qdY5x2EDzE+T2h238XQN0hF+jzhPxNPEV4vIlIjOgW7iIiIiEgJdERbRERERKQEarRFREREREqgRltEREREpARqtEVEREREStCvy/stQPgU+dPoU94iIiIiUo7RhKVWG6sZDdGvjfa7CMtaiYiIiIiUbTNSy5A29Guj/TTAc8+9xKxZs5cvHD9+LNOmzeh456LjlHvkc1ehxrrmrkKNyq3XhXJXq8a65q5Cjf2ee9SoAZZYYhGIvWezfm20ZwLMmjU4pNFubMui6Djl7t045e7dOOWuV+4q1FjX3FWosa65q1BjTXK3nKqsD0OKiIiIiJRAjbaIiIiISAnUaIuIiIiIlECNtoiIiIhICdRoi4iIiIiUQI22iIiIiEgJ1GiLiIiIiJRgYHAw+zqEFbIK8Mi0aTNYaNwoFp5/4SE3vvz6y7z0wpzLHS6y2OhMsSMRV9fc2je9m7vX9k03c2vf9G5u7Zvezd1r+6abubVvejd33n3zyvRZjB8/FmBV4NHm+/XrCWvesvD8CzNw5MCQbYNHDPIS0+c6diTi6ppb+6Z3c/favulmbu2b3s2tfdO7uXtt33Qzt/ZN7+bOu29eYfizSXa90TazSwjvAmYBM4AD3f0eM3sUeDVeAA5z9z92pUgRERERkZy63mgDe7n7CwBmtj1wJrBhvG1Hd/9b1yoTEREREZlLXf8wZKPJjhYjHNkWEREREam0XjiijZn9DPgQMABsnbrpfDMbAG4Evunuz3ehPBERERGR3Hqi0Xb3zwKY2R7AD4CPAJu5+xQzWwA4ETgF2D3PuPFToC1NmDAu8zhZY4uOq2vuKtRY19xVqLGuuatQY11zV6FG5e7dOOXu3TgYvteEHmm0G9z9PDM7w8zGu/uUuO01MzsNuCzveNOmzWj7BEydOucnSts9sc2xIxVX19zaN72bu5f2TTdza9/0bm7tm97N3Yv7ppu5tW96N3eefTNcrwldnqNtZmPNbMXU9e2AZ4FXzWyxuG0A2BW4pytFioiIiIjMhW4f0V4EuNjMFgFmEprs7YBlgN+Y2WhgNPAAsH/XqhQRERERyamrjba7/xt4b5ubNxjJWkREREREitT15f1ERERERPqRGm0RERERkRKo0RYRERERKYEabRERERGREqjRFhEREREpgRptEREREZESqNEWERERESmBGm0RERERkRKo0RYRERERKYEabRERERGREqjRFhEREREpgRptEREREZESqNEWERERESmBGm0RERERkRKo0RYRERERKYEabRERERGREqjRFhEREREpgRptEREREZESqNEWERERESmBGm0RERERkRLM1+0CzOwSYFVgFjADONDd7zGzBDgHGA9MA/Z094e6VqiIiIiISA69cER7L3dfz903AI4HzozbfwKc6u4JcCpwercKFBERERHJq+uNtru/kLq6GDDLzJYGNgR+Gbf/EtjQzCaMdH0iIiIiInOj61NHAMzsZ8CHgAFga2BF4El3nwng7jPN7Km4fWrXChURERERyagnGm13/yyAme0B/AD4VhHjjh8/tu1tEyaMyzxO1tii4+qauwo11jV3FWqsa+4q1FjX3FWoUbl7N065ezcOhu81oUca7QZ3P8/MzgCeAFYws9HxaPZoYHlgSp7xpk2b0fYJmDp1+hzb2j2xzbEjFVfX3No3vZu7l/ZNN3Nr3/Rubu2b3s3di/umm7m1b3o3d559M1yvCV2eo21mY81sxdT17YBngWeAe4Dd4k27AZPdXdNGRERERKQSun1EexHgYjNbBJhJaLK3c/dBM9sPOMfMvg08B+zZxTpFRERERHLpaqPt7v8G3tvmtr8D7xnZikREREREitH15f1ERERERPqRGm0RERERkRKo0RYRERERKUHmRtvMVjKzRTvEjDOzlea9LBERERGRastzRPsR4MsdYg6KcSIiIiIitZan0R6IFxERERER6aDoOdrLAi8VPKaIiIiISOUMu462mTWfJGb9FtsARgMrAbsDfy2oNhERERGRyup0wpqzgcH4/SCwfbw0a0wpeRk4spDKREREREQqrFOjvU/8OgCcCVwCXNoibiYwDbjF3Z8vqjgRERERkaoattF293Ma35vZXsAl7n5u6VWJiIiIiFRcpyPab3H3LcosRERERESkn+jMkCIiIiIiJch8RBvAzDYHDgXeDSxB60Z90N1zjSsiIiIi0m8yN8Rmti3hw5CjgccBB94spywRERERkWrLc+R5IvAGsK27X11OOSIiIiIi/SHPHO21gQvVZIuIiIiIdJan0Z4BPFtWISIiIiIi/SRPo30d8L6yChERERER6Sd5Gu3DgNXM7HAzG+gYLSIiIiJSY3k+DHkEcD9wJLCvmd0DPN8ibtDdP5NlQDMbD5wHrAa8DjwEfMHdp5rZIPBXYFYM38Pd/5qjXhERERGRrsnTaO+d+n6VeGllEMjUaMfY49x9EoCZ/QD4fur+73f3GTlqFBERERHpCXka7VWLTu7uzwKTUptuBb5YdB4RERERkZGWudF298fKLMTMRhGa7MtSmyeZ2XzAlcBEd3+tzBpERERERIrSS6dKP5mwhOAp8fpK7j7FzBYlzOP+FnB4ngHHjx/b9rYJE8ZlHidrbNFxdc1dhRrrmrsKNdY1dxVqrGvuKtSo3L0bp9y9GwfD95qQ7xTsK2WNdffHs8bGsY8HVge2c/dZcYwp8euLZvYz4OA8YwJMmzaj7RMwder0Oba1e2KbY0cqrq65tW96N3cv7Ztu5ta+6d3c2je9m7sX9003c2vf9G7uPPtmuF4T8h3RfpTw4cVOBvOMa2ZHAxsRTu3+Wty2BPCqu78Sp47sCNyTo1YRERERka7K02ifS+tGe3FgfWBlwgcbM8/lNrN3At8AHgRuNjOAR4DjgNPjEn9jgJsJU0dERERERCohz4ch9253W/wg47eA/YC9cox5P9Du5DfrZh1HRERERKTX5DkzZFvuPsvdjyRML/l+EWOKiIiIiFRZIY12ys3AhwoeU0RERESkcoputJcEFil4TBERERGRyims0TazLYFdgL8VNaaIiIiISFXlWYbvT8OMsSLQWGf7O/NalIiIiIhI1eVZ3u+DbbYPAs8BfwSOd/d2DbmIiIiISG3kWd6v6PncIiIiIiJ9S82ziIiIiEgJ8kwdGcLMxhHOCvmCu79YWEUiIiIiIn0gV6NtZvMBhwCfBVZNbX8E+BlhjvabhVYoIiIiIlJBmaeOmNn8wNXA94BVgCnA7fHrKnH7tTFORERERKTW8szRPpiw8sjvgTXdfRV3f5+7rwIYcDmwWYwTEREREam1PI32pwgno/m4uz+UvsHdHwY+CdwPfLq48kREREREqilPo/0O4Ep3n9Xqxrj9SmC1IgoTEREREamyPI3268DYDjGLAG/MfTkiIiIiIv0hT6N9H7CjmU1odaOZLQXsCNxbRGEiIiIiIlWWZ3m/U4BfAbeb2VHAn4GngWUJH5I8HJgAHFRwjSIiIiIilZPnFOwXmdn6wNeBM1qEDADHuftFBdUmIiIiIlJZuU7B7u7fBN4PnAlMBv4Zv54JbOLuXy+8QhERERGRCsp9CnZ3vxW4tYRaRERERET6Ru5Gu0hmNh44j7Ak4OvAQ8AX3H2qmb0XOB1YCHgU2N3dn+lWrSIiIiIieQw7dcTM5jez283sOjMb0yHuOjO7dbi4FgYJ87rN3dcBHga+b2ajgF8AB7h7AlwPfD/HuCIiIiIiXdVpjvbuwEbAD9297frY7v468APg3eQ4M6S7P+vuk1KbbgVWjjlfdfcb4/afADtnHVdEREREpNs6TR35JPBPd/9Dp4Hc/SozewjYCTg7byHxKPYXgcuAlYDHUmP/x8xGmdmS7v5s1jHHj29/fp0JE8Zlri1rbNFxdc1dhRrrmrsKNdY1dxVqrGvuKtSo3L0bp9y9GwfD95rQudHeAOjYZKdcD3wkR3zaycAMwnrdn5jLMYaYNm1G2ydg6tTpc2xr98Q2x45UXF1za9/0bu5e2jfdzK1907u5tW96N3cv7ptu5ta+6d3cefbNcL0mdJ46shTw7w4xaf8GxueIB8DMjgdWB3Zx91nA44QpJI3blwJm5TmaLSIiIiLSTZ0a7VeA4Y+JDzUWeDVPAWZ2NGFO9sfd/bW4+S5gITPbNF7fD7g4z7giIiIiIt3UaerIFGDjHONtTDganYmZvRP4BvAgcLOZATzi7p8wsz2A081sQeLyfjnqEBERERHpqk6N9iRgfzPb2N3vHC7QzDYinDXy5KzJ3f1+wqnbW912M7BO1rFERERERHpJp6kjpxDWur7YzNZsF2RmaxCmdswETiuuPBERERGRahr2iLa7u5l9B5gITDazXwN/Ap6IISsA/w/YAVgA+La7e3nlioiIiIhUQ8dTsLv7d8zsTeAI4FPAbk0hA8AbwP+4+zHFlygiIiIiUj0dG20Adz/azM4H9gU2AZaLNz0N3Aic5e6Ptbu/iIiIiEjdZGq0AWIjfUSJtYiIiIiI9I1OH4YUEREREZG5oEZbRERERKQEarRFREREREqgRltEREREpARqtEVERERESqBGW0RERESkBJkbbTNbycwW7RAzzsxWmveyRERERESqLc8R7UeAL3eIOSjGiYiIiIjUWp5GeyBeRERERESkg6LnaC8LvFTwmCIiIiIilTPsKdjNbM+mTeu32AYwGlgJ2B34a0G1iYiIiIhU1rCNNnA2MBi/HwS2j5dmjSklLwNHFlKZiIiIiEiFdWq094lfB4AzgUuAS1vEzQSmAbe4+/NFFSciIiIiUlXDNtrufk7jezPbC7jE3c8tvSoRERERkYrrdET7Le6+RRkFmNnxwA7AKsA67v63uP1R4NV4ATjM3f9YRg0iIiIiIkXL3Gib2RLAcsDD7v5aavs+wMcJq42c6O6356zhEuBHwA0tbtux0XiLiIiIiFRJnuX9jgZuS9/HzA4EfgZsB+wKTDKztfIU4O43uvuUPPcREREREel1eRrtTYDr3P2V1LZDgCeBDwA7x20HF1QbwPlmdp+ZnWZmixc4roiIiIhIqTJPHQFWAK5rXIlHrlckzJ2+MW7bidB0F2Ezd59iZgsAJwKnENbpzmz8+LFtb5swYVzmcbLGFh1X19xVqLGuuatQY11zV6HGuuauQo3K3btxyt27cTB8rwn5Gu2FmP3BRAhHuAeBa1PbHgY+mmPMthrTSdz9NTM7Dbgs7xjTps1o+wRMnTp9jm3tntjm2JGKq2tu7Zvezd1L+6abubVveje39k3v5u7FfdPN3No3vZs7z74ZrteEfFNHngTWSF3/MPAicG9q2xJAemrJXDGzRcxssfj9AGH+9z3zOq6IiIiIyEjJc0T7z8BeZvYlwpHtjwG/cfdZqZjVgFwfbDSzk4BPAssC15rZNMKHK39jZqMJp3d/ANg/z7giIiIiIt2Up9E+hrDe9Y8IZ4qcAUxs3GhmiwKbAmflKcDdDwIOanHTBnnGERERERHpJXlOWPOImb0T2DFuuszdH0+FvAM4HbigwPpERERERCopzxFt3P1fhNU/Wt12N3B3EUWJiIiIiFRdng9DioiIiIhIRm2PaJvZtwnL953q7s/G61kMuvt3C6lORERERKSihps6MpHQaF8IPEvqg48dDAJqtEVERESk1oZrtLeIXx9vui4iIiIiIh20bbTd/S/DXRcRERERkfYK/zCkmeVayUREREREpB9lbrTN7KdmtmCHmFWBG+e5KhERERGRistzRPszwO1mtkarG81sB8I62u8qojARERERkSrL02h/D1gLuNPM9mlsNLP5zew04CJgJvCJYksUEREREamezI22u38L+DAwHfiZmZ1nZhsDtwP7ATcD67v7ZaVUKiIiIiJSIbk+DOnu1wHrA9cCnwJuA94JHAVs7u5PFF2giIiIiEgVzc0KIdOBqcBAvP4C8Bd3n1VYVSIiIiIiFZfriLaZrUf4wONuwNWEKSPzA380s++ZWeHLBYqIiIiIVFGe5f2+BNwCvB34prtv7e5nABsB9wFfB24wsxVLqVREREREpELyHIE+CXiGMBf72MZGd38IeC9wGvA+4J4iCxQRERERqaI8jfalwAbufkvzDe7+ursfCOxQWGUiIiIiIhWW+cOQ7t5xfWx3/52Z3TlvJYmIiIiIVN/crDqCmS0CJMBYd78hfZu7TymiMBERERGRKsvVaJvZ24AfAdsBo4HBxhhmtilwBrC/u0/KON7xhOkmqwDruPvf4vYEOAcYD0wD9oxzwUVEREREKiHPqiPLEU5Qsz1wBWEFkoFUyG3A0sAuOfJfAnwAeKxp+0+AU909AU4FTs8xpoiIiIhI1+X5MOQRhEZ6K3f/JHBN+kZ3fwO4Adgk64DufmPzVBMzWxrYEPhl3PRLYEMzm5CjVhERERGRrsrTaH8EuMzd/zxMzOPA8vNWEisCT7r7TID49am4XURERESkEvLM0V4G6DRP+g1gkbkvp1jjx49te9uECeMyj5M1tui4uuauQo11zV2FGuuauwo11jV3FWpU7t6NU+7ejYPhe03I12g/S+ejygnwrxxjtjIFWMHMRrv7TDMbTThKnns1k2nTZrR9AqZOnT7HtnZPbHPsSMXVNbf2Te/m7qV9083c2je9m1v7pndz9+K+6WZu7ZvezZ1n3wzXa0K+qSM3AR8zs2Vb3WhmqwNbA8NNLenI3Z8hnF1yt7hpN2Cyu0+dl3FFREREREZSnkb7B8CCwF/MbBtgYQhrasfrlwOzgB9mHdDMTjKzJ4C3Adea2f3xpv2AA83sQeDAeF1EREREpDLynBnyNjP7AvBjwvJ+DS/Gr28C+7r7/XPcuf2YBwEHtdj+d+A9WccREREREek1eY5o4+5nAmsDJwG3Aw8DdwOnAeu6+/mFVygiIiIiUkG5T8Eez9D4lRJqERERERHpG7mOaIuIiIiISDZqtEVERERESqBGW0RERESkBGq0RURERERKoEZbRERERKQEarRFREREREqgRltEREREpARqtEVERERESqBGW0RERESkBGq0RURERERKoEZbRERERKQEarRFREREREqgRltEREREpARqtEVERERESqBGW0RERESkBGq0RURERERKoEZbRERERKQEarRFREREREowX7cLGI6ZPQq8Gi8Ah7n7H7tXkYiIiIhINj3daEc7uvvful2EiIiIiEgemjoiIiIiIlKCKhzRPt/MBoAbgW+6+/NdrkdEREREpKNeb7Q3c/cpZrYAcCJwCrB71juPHz+27W0TJozLXETW2KLj6pq7CjXWNXcVaqxr7irUWNfcVahRuXs3Trl7Nw6G7zWhxxttd58Sv75mZqcBl+W5/7RpM9o+AVOnTp9jW7sntjl2pOLqmlv7pndz99K+6WZu7Zveza1907u5e3HfdDO39k3v5s6zb4brNaGH52ib2SJmtlj8fgDYFbinq0WJiIiIiGTUy0e0lwF+Y2ajgdHAA8D+3S1JRERERCSbnm203f2fwAbdrkNEREREZG707NQREREREZEqU6MtIiIiIlICNdoiIiIiIiVQoy0iIiIiUgI12iIiIiIiJVCjLSIiIiJSAjXaIiIiIiIlUKMtIiIiIlICNdoiIiIiIiVQoy0iIiIiUgI12iIiIiIiJVCjLSIiIiJSAjXaIiIiIiIlUKMtIiIiIlICNdoiIiIiIiVQoy0iIiIiUgI12iIiIiIiJVCjLSIiIiJSAjXaIiIiIiIlUKMtIiIiIlKC+bpdwHDMLAHOAcYD04A93f2h7lYlIiIiItJZrx/R/glwqrsnwKnA6V2uR0REREQkk549om1mSwMbAlvFTb8ETjGzCe4+tcPdRwOMGjUAwMqLrTxHQOO2ZlljRyKurrm1b3o3d6/tm27m1r7p3dzaN72bu9f2TTdza9/0bu653DejW91nYHBwsOVg3WZmGwHnuvs7U9seAHZ397s73H1T4IYy6xMRERERiTYDbmze2LNHtOfRHYQH/DQws8u1iIiIiEh/Gg0sR+g959DLjfYUYAUzG+3uM81sNLB83N7Ja7R4VyEiIiIiUrCH293Qsx+GdPdngHuA3eKm3YDJGeZni4iIiIh0Xc/O0QYwszUIy/stATxHWN7Pu1uViIiIiEhnPd1oi4iIiIhUVc9OHRERERERqTI12iIiIiIiJVCjLSIiIiJSAjXaIiIiIiIlUKMtIiIiIlICNdoiIiIiIiXo60bbzBY1s1Hx+7XNbFczm7/bdQ0nrh1e5HhLFjleHHN8h9sXN7OxGcZZ3MwWL6ywktVp31RNPz6mdvRzo5+bopjZ0mb23m7XIXPqx9dbXfX1OtpmdhfwAWAccBfwN+Bpd9874/2vdPdt4vcLAIcAKwOXuvvvU3Enu/uB8fuVgP8FZgIHAd8C9gDuA3Z390dT91u4Rdr7gbWAAXd/Oca9093vj9+PiWNuQjhz5rdScYcDZ7j7M2a2FnAZsBwwDfiEu9+Vyn0ncD7wi+HOtmlmmwKnA1OA/YFLgNWAF4Ad3P2WGLc4cAzwaWCRePcngR+4+8mp8ZYCjgV2BgbiZSZwMfD1rGf+1L4pZd8sCBwK7AK8LW6eAlwEHO/ur7SrpamuM9z986nrnybsm9+7+72p7d9w92Pi94vF524W8B3gi8DuwF+Bg9z92Q45/+nub2/atoS7P5e6vi+z980p7j4Yt+8DXO7u/zGztxFOkvUu4F5gb3d/ODXGrwn75nJ3f3OYetYEjic8f98AzgU+SPgdtI+7/z3GjQEOBj4Vn6M3gQcI++by1Hj6udHPTWP7PP3cmNkNwEcJr6H7geeBP7j7ofH2vvm5ibHzvH/0Oy37vunwmPZx97Oatq1E2C93uftrqe1bufs1qesfBWa5+x/iz/BOwF/d/Wcdcl7h7h/tEGPAu4H70vsz3rYO8Ii7z4ivu8Ni7L3A0VleP319RJvwi/0lwi+Vn7r7h4GN0gFmtnC7C7B2KvQ0YB3g78CxZnZi6rZNUt//BPgL4Y/Q1cATwOrAhUD6PgAzgOnxa+OyMvBS3N5wXur7I4F1CX/4xjeNuUs8dT3AccCh7r4I4Yf7pKbcyxHehDxqZr81s20bR/+bnAB8HbgAmAR8N4756VhDwznxsW4et/8PsAOwjZkdmYr7BfBPYBV3HxvHejvwSLztLdo3I75vzgJWAvYiPC+rA3vHbWe3yN/O1o1vzOxYYD9gWeAPZvbfqbidUt+fQfh9tDihmVoF+DzwFE37xsyeab4AK6W+b7gudZ9DgM8Bk4HtgKNTcV919//E738IXEFovH5KaMjSNif88XzSzE4ws7Vp7XTgKsLzfj3hdbdafJw/bnrcqwETgSuBU4GTgYlmdkAqTj83+rlpmKufm5Sx7v4C4e/i+YTXwNap2/vp5waK2T/6nZZ93wwn/XPTeMNyF+F3zINm9r7Uzcem4r4bazzKzI4HjiI8j7ub2cRU3EXNF2Dz1PeNuN+kvv8I4ffA9sAVZrZ7U80XAG/E748B1iP8/lqO8Du0o/myBFXYgvGozVbAKXHbzKaYGcAg4d19Q+N6+nD/u9x9XQAz+zHwSzP7OfDZpvsu7+4nxbgDGu9ugZPN7LNNuc8mvNv9irtPj/d5xN1XbYpLj7818IH47uoqwjvZhvS0mOXc/XcA7n69zXmk6Rl3/4SZLU04OnUscIaZnQec6e4PxrgxjSMEZvYdd784jvnn+Nw2vN3dt4/fTzazW9z9+2b2ScIf6CPibau4e/qXOvEXwlFm5k01at+M7L7ZyN2TplqmAp8zswfTG5t++Tc/H4unrm8LbODub5jZUcClZraYux/J0OduTXffxcxGA/8GtnL3mWZ2O+HIQdp9hAbz+4QjWQPADcCmLWpp2AXYJh7hORO4nXBUBob+Hlzd3XeJ359rZl9pGvMJd9/QzDYE9gH+YmYPA2cCF7j7izFu0cZRTzP7grsfH7efZWYHpcZ7j7uvFeMuBya5+xFmdi1wC6GBAP3cgH5u5vXnpqHxGLcAfuXus8wsfSSzn35uIOP+0e+0YvZNuqFtUXvztK9DgfXd/Ukz+yDwKzP7nLtf3fRYPw6sDywM/AtY0d2fNbNTCPt7Yoz7APB7whuBRs4t4ra09H8KvkZ4Hu8xs5UJ/+FKH7wYSB1p34Lw2nvTwn8C7mnzWIfo9yPaFxJ2yqrATWa2LPBqU8zTwDLuPip1Ge3uowjvmBreeuHGfxXsQPh34nkMfR7Tf8jubso1ZJ6Ou+9L2KnXmdnWrWKiATNbKP5hedPdZ8T7v8nsd1oAd5nZgfH7yWb2fgAL/3J9vVUt7v6Mu//Q3deOj2lJ4LZU3GgzW8rMVgOWMLN3xDEnMPsXNsAsi3Mn44t1VBz/1aYaX21610q8z/uB15o2a9+M7L6ZaWZD/lUZ77MaoXka8riBLQn/jmy+DPmD5e5vNB4P8CFgCzM7hqHP55sxZiYwJX7Fw79CZzWNtyXhD9XZhF/+jwJvuPtj7v5YKjQ9/mBsTPEwLSH9uB82s+3i9/8ws9Xj4162+blg9r6528PUiuUIR0g/QZhW0DDGzBa0MOVjidj8NaZWLJiKm2nhX9sAiwILxfGfQz83oJ+bwn5uUiaZ2QPAZvH7xRl6AKqffm4asVn2j36nFbNvtgWuITS3zZfm/mvA3Z+M+ScB2wCnW5gmkn6sb7j7zPjm/R8ep914mLGQfu2uQ5gqvBFwsbufDcxw93Pc/Zzmxxwt6u73xPHSz3XDK43fEYRpVo3HOh8ZD1b39RFtdz/SzE4CXojv2mcQfvGm/Znw79RJLYa4PfX9v8xsPY/zd+I7008R/r2Y/lfLK2Y2zt2nu/u2jY0WPmwzx/wnd7/CzG4BTjGzXWm9T9YlHKUaAAbNbIX4DnBBhv5BPAA4O75jfZLwS/Rxwr9t92kac6DpOu5+K3Br05GDE4HGfK79gHPM7DlgQ8K/ctNx95nZZMIvpoPi414GSL949wPOM7NXUttXIbx492gqSftmdi0jsW++RnhDegdD983GhH95pt0JLOXu9zXXambpX84vmNlqHucEuvt0M9uG8K/MdVJxM81sQXd/1d03SI21CC24+ylm9kfgp2Y2idYHDdaxcJRqABhnZkvFoz/NvyD3B35nZl8FngVut/D5jhWBA5vGHLJv3P114FeEIzFvS910PmFKxnyEI5+/NrP7CEeoLk3FXUDYrzcQ/vN2anzcyzD0j4F+bvRzM88/N9EBhH9//9PDUdn5CFMQGvrp5way7x/9TqOQfTMZuMfd72gu3sIUkOZti7v78zH3A2b2IcIUlfTR71FmNhDfpOybuu8AMCZV+1RgZwtTUv5iZl+j9Rv9VS0ceR8AVjCzBXz2UesxTbGHAdeY2TmEN0PXmtkVwH8Rfld21NcfhgQwsw8T3qUCXOPhXxJzM87qwOvN73jijt7G3f/QuB5fDM33XwpY1t3/NkyOnYAPunvzHLN28YsDa8Q/Junt7yB8+Gg08LinPjCUinmfxw/9ZMizJOGd5zQzG0d4B/+Iu9/dFLcG4Q/0ve7+0DDjDRDeca4UNz1O+CDEXL0YtW8K3TeLEI4qpPfNVY0jjqm4+YGZjaM0w4z3PuBFjx98S21fAPiMu58Wry8L/MebPowTf9Gbu19HC3EfH0KYerBd020rN4U/FRuLCcCmHqchpOK3JLVvgCvjkaJ0zA7u/hsyMLP1CEed7rPwgZ+dCPvmt01xHyI0nne5+5+HGa+KPzc7A5tX+OdmTeCddOfn5gV3f6Bpe6ufm6nN4w33c2NmF7n7zu22VejnZivCG4Zhf25ibMf90wv7Jt4+QJhSsVmG32lPu/vrvbRvYsy/3f1fLe6/cvr3jYWpZw+6+/VNcW8Hvp96TX4YuKFF7asD2/vsaSzp25YnzB9/n7uPb7ptr6bwyz1MRVkeOMDd/6fFWPsz9Lm8IOvvm75utM3sUMIHIH4ZN+0KnNNqpzTdb2nC/LxbRzKuzrlFRPqFma3hGVZhyBNbVJyZ3e3uGzZtu8/jfP2RqLGMMfPkFhlJ/d5o3wds4rM/lDMOuKnVLxTrsORRWXF1zt2ilreWHisqtui4fs5tGZd7yxNbdFyL2Mvc/You5c46ZhE15llib2XCHMthY7OOmXW8YcZsLGmWe8ycjzvr4yk6LtOShnlii46LsZ8jTJVYk7AUXsNigLv7x0rM3c3HnXUpya7EtYidHzg8w5hZ4/Lkzvp42uZOjXsw8HN3f8HCB5LfRVjWcI5ZBVlj5zLuXMJyfHM9Xt7YZn09R5vwA/fWklIe5lLNMY8vGhufwN0Jc5G+TpiP09wgFh1Xq9xtfkE2DFlWKGts0XE1zn0a4cNwtxOWe9vK3f873rZJ0/2yxhYd1xz7fTPbsku5s45ZRI0/IcxbXJSwxN4vCcuU7UyYS/zxVOyPM8ZmHTPreO3GTOZhzDyPO2ts0XGtVnmBMI98kPCvZnLGFh1HfAwPEVbgSv/efpHw5qGsGssYM0/u8wjz7yEsL7cW4Q3UjoT9+PkuxzXHTsw4Zta4PLmzPp7hcjfs7e4nmNkWwNKEudUnEV6HzbLGzk3cMgWMlzd2iH5vtO8ws7MIa0cCfIbwgYdWOi15VFZc3XJnXXosT2zRcXXNnXW5tzyxRcfVNXeeJfayxhYdV9fcZ5NtScM8sUXHNVZUeMzM1vHh5/UXnrubj5vsS0l2K67fcjc05qZvAZzv7jdb63Xt88R2Ky5v7BD9vrzfgYRleU6Kl6nAl9rETrLhlzwqK65uubMuPZYntui4uubOutxbntii4+qaO90YDbvEXo7YouNqmduzL2mYObbouCY3mNkSjStmtqSZvfVhtDJyd/lxZ11Ksltx/Za74RUzOwzYDbjawmyC+VvE5YntVlze2CH6utF295fc/TB33zhevu5h3cVWDiCcznVjD2tkNi95VFZc3XL/maapEim3N13PGlt0XF1z/8vCJ8aBt9Z//RThD1jz/bPGFh1X19yvWPiMCd55ib2ssUXH1Ta3hzn42wB7mdnZDPPf4qyxRceljPXUabw9rEk8ruzcXXzcjaUkZwAbmdkKADbnUpLdiuu33A17E9bkPszDCiRvJ0wnbSVrbLfi8sYONTg42LeXJEmWTpLkF0mSXB+vr5skyX5tYi/qxrY659alty5JkqyeJMnKLbYPJEnykbmJLTqurrmTJBlos8+WSpJk7eb7ZoktOq7OuZtu3ylJklPb3T43sUXGJUlyX5IkC6euj02S5G8jVWO3HneL+yyeJMl7ezWun3InSTJ/kiTLZsybKbZbcXljBwcH+77RvjRJkv2SJLkv9eTc1yb27hbb5ogtOq7OuVO3L53jhz9TbNFxdc1dhRrrmrsKNdY1dy/XmCTJN5IkuSlJkt3j5aYkSb7e74+7F3JXocaixkyS5FdJkiyWJMlCSZI8mCTJs0mSHDIvsd2KyxvbfOn35f3udPeNzWyyxzMzmdk97r5+KibrkkeFxtU5d4yvxBKEdcxdhRrrmrsKNdY1dxVqTMXvRThVNsAV7n5u2TV2+3HrdTHiuSe7+wZmtiPhpIEHA7d66+WVM8V2Ky5vbLO+nqNN0zw6Cx/Ma15F4GrCUkePxq+Ny67AJ0qMq3NuiMsAEn5gzyecunbrFnF5YouOq2vuKtRY19xVqLGuuatQIwDufo677xwvczTZJeau43NehRrLGHNM/Lo5oRF/mbBSTCtZY7sVlzd2iH5vtH9rZqcD48xsb0IzeGY6wN0fc/dJwDru/pfUZbKnTp1adFydc0fpZQCvcfdZzPnhpryxRcfVNXcVaqxr7irUWNfcVagRM0vM7EYzeyRe39DMJo5E7hLGrELuKtRYxpgPmNmVwHaE1WEWapM3T2y34vLGDtHXjba7HwdcD9wFfAQ4yd1/1CZ82CWPSoyra+5eXoKw7rmrUGNdc1ehxrrmrkKNEE6SdBTwQrx+D7DTCOWu43NehRrLGHMv4HRgCw+rvS1JOIFdK1ljuxWXN3aIvm60Adz9fHffxcO/yH4xTGjHJY9Kiqtr7l5egrDuuatQY11zV6HGuuauQo0Ai7n7VcR1p+MRyddHKHcdn/Mq1Fj4mO7+irtf4u6PxOtPxtfdHLLGdisub+wcsnxismqXJEkuTpLkonaXNvfJtORR0XF1zd1qPwyzb2q5/GG3clehxrrmrkKNdc1dhRrj9luTJBmTxBWikiRZIUmSu2rwuHvmNdBrNZaUZ70kSW5JkuTlJElmNi5tcmeK7VZc3tjmS6eF7avqivj13fHSOJL9KeY8OUjDL4FrLJwGGeCLqfuVGVfX3O9osW2NNjVmjS06rq65q1BjXXNXoca65q5CjRCmjvwOWMrC3Ow9gf8Zodx1fM6rUGMZY54GHA6cQPiw5AHA9Da5s8Z2Ky5v7BB92Wi7+zkAZvZ54AMeTm2MmZ0BXNvmPseY2VNAYxm6073Fp7GLjqtbbpu9DGBiZuk3PYsBnh4ra2zRcXXNXYUa65q7CjXWNXcVakxz93PN7J+ED3UtDOzl7jf06+PW62Jkc6cs6O7Xmdkod38aONzM7gCOnYfYbsXljR2iLxvtlAnAa6nrr8dtLcUG/ZxOgxYdV7PcVwMPAacQlv9reBG4by5ji46ra+4q1FjX3FWosa65q1DjEO5+I3Bjm5v77XHrdTGyuRsaK5E8a2brAU8AS7WIyxPbrbi8sUNlmV9S1UuSJKcnSXJVkiS7xcsfkiQ5vU1skiTJjUmSPBKvb5gkycSy4+qaO2lzeuM2NWaKLTqurrmrUGNdc1ehxrrm7vUakyQ5Nn5t9RmmC5MkOS1JknX77XF3O3cVaiwp98FJkoxPkmTrJEmmJ2Fuc7uzLmaK7VZc3tjmS7+vOvIl4PfAjvHy+7itlaxLHhUdV9fcVViCsK65q1BjXXNXoca65u71GhtHsK8g/C1MX/4APAJcUGKNZYxZhdxVqLHwMd39BHefFlfmWBJYxt2Pb5U4a2y34vLGNuvrRtvd33D3k919h3g5NS5H00rWJY+Kjqtr7iosQVjX3FWosa65q1BjXXP3dI3ufnn8ek6byw+A35RYYxljViF3FWosbEwzW6v5AqwOrBi/J29st+LyxrbTl422mX05fv2BmR3XfGlzt5lmNobYIJrZCrQ+vWbRcXXNPcrMFm5cMbOxzD7F6dzGFh1X19xVqLGuuatQY11zV6FGzGw5M7vYzP4TLxeZ2XIA7n5EmblLGLMKuatQY5FjNv+3JH25ommsrLHdissb21K/fhjy1fh1EJgBDGS4T9Ylj4qOq2vuKixBWNfcVaixrrmrUGNdc1ehRoDzCGdM/nK8vm/ctuUI5K7jc16FGgsb091XBTCzrYA73P35eH1xYKP0QFljuxWXN7adgcHBwSxxlWRmU4FLgbM9fMq6U/ymhCWPBoDLPbXkUZlxdc1tZnsB28arV3ibJQjzxBYdV9fcVaixrrmrUGNdc1ekxvvd/Z2dtpWRu6TH0/O5q1Bj0WOa2WRgQ3dv/Hd7FHCnu284t7Hdissb26zfG+0lCSep2RtYFDgbONfdn+hiWSIiIl1hZpcCX3X3f8TrqwHHu/snuluZ9BMzu8fd12/adq+7rze3sd2KyxvbrF+njgBvTdI/BTjFzNYGvkr4ZPVb84nM7Fh3P8zMLibOK04ZBKYBPwE+XWScu99X19wAZpYAZwIruPuqZrYh8DF3n9h038yxRcfVNXcVaqxr7irUWNfcvV5j6nfzQsC9Ztb4L+8mwE1l19itx93t3FWosaQxp5vZe9z9tni/9wAvNefNGdutuLyxQ/TlhyHTzGyUmX0UmEj4V8fZTSFZlzwqOq7OuaEaSxDWNXcVaqxr7irUWNfcvV5j43fz+cD+hN/HFxBOJX0Bc+qXx93t3FWosYwxvwZcYmbXmtm1hM9uHdwmd9bYbsXljR0q62LmVbwkSXJCkiRPJklydZIkn06SZKG5HOfIbsT1c+4kSe6IXyentk1uc79MsUXH1TV3FWqsa+4q1FjX3FWoMc+l3x63XhcjmztuXyJJko/EyxKtYvLGdisub2z60tdTRwjTFd7r7lM6BVpY3ugkYIu46U/Al939aU8teVR0XI1zV2EJwrrmrkKNdc1dhRrrmrsKNaankAzh7juXnbuEMauQuwo1ljKmh/W2/9Am31zFdisub2xaX08dcffvZWmyo/OAvwLrxst9cVvZcXXNfRpDlwG8AWh3lqWssUXH1TV3FWqsa+4q1FjX3FWoEYZO77sOWAJ4eoRy1/E5r0KNZY0p9PmqI3lYxiWPit5W89w9vwRhXXNXoca65q5CjXXNXYUaW9xvfuBqd//gSOSu43NehRrLGlPo7znaeS5JklyaJMk7UtdXS5Lkd2XH1Tm3Lrrooosu3b0kSTImSZKHul2HLrr066Xf52h3ZBmXPCo6rq65LeOygl7j5Q+7lbsKNdY1dxVqrGvuKtTocVlVmGOO9ihgPeDa1O2F1tjtx63XxcjmTr/WJKh9o83Qc9Wfn/q+ebmjouPqmju9DGArS8f7rJ0j9hsFx9U1dxVqrGvuKtRY19xVqHHt1LZ07BuEk9XcmtpWdI3dftx6XYxs7rXb3F5f3T6krosuzZekR5YgVO5q1ljX3FWosa65e6nGJEl+lSTJYkmSLJQkyYNJkjybJMkhWeur6uPuxdxVqLGsMet00Ychozb/DpljyaOi4+qa24ZZBrBFjZlii46ra+4q1FjX3FWosa65q1BjjJ3s7huY2Y7AloSTbtzq7uv2+ePW62IEc8tsfb28X05ZlzwqOq6uuauwBGFdc1ehxrrmrkKNdc1dhRoBxsSvmwN/cPeXab0Ocr89br0uRja3NHT7kHqvXpIkmT9JkkkjHVeX3EmS3J9lW57YorfVNXcVaqxr7irUWNfcVagxbr8oSZIrkyR5NEmSReIUkntq8Lh75jXQazWWNaYu4aIj2u0NAit0Ia4uuf9hZu9oXDGz1YAH24yRNbbouLrmrkKNdc1dhRrrmrsKNQLsBZwObOHuLwFLAl8fodx1fM6rUGNZYwpadeQt1mHJo7Li6pY7dXvPLkFY19xVqLGuuatQY11zV6HGNHd/Bbgkdf1J4Ml+fdx6XYxsbpmTGu3Z0kvWtFryqKy4uuVO396rSxDWNXcVaqxr7irUWNfcVagxj3573HpdjGxuaaJVRyIz+xXwBeB14F5gKeBodz++zLg65xYRERHpZzqiPZu5+wsWljz6E3HJI6C5QSw6rpa5m6aYvKWXliCsa+4q1FjX3FWosa65q1BjHv32uPW6GNncMpsa7dnmWPLIzFoteVR0XF1zp/8NtSCwI/BAmxqzxhYdV9fcVaixrrmrUGNdc1ehxjz67XHrdTGyuSXS1JHIzC4CxgFrAu8krCt6i7uvX2ZcnXM33W9+4Gp3/+BwcXlii46ra+4q1FjX3FWosa65q1BjHv32uPW6GNncdabl/WbLuuRR0XF1zp02SO8tQajc+eKUu3fjlLt347qdO6t+e9x6XYz8mLWkqSORd1jyqKy4uuZumufVU0sQ1j13FWqsa+4q1FjX3FWoMY9+e9x6XYxsbplNjbZ0S3qe1xv01hKEdc9dhRrrmrsKNdY1dxVqzKPfHrdeFyObWyJNHZFu2YZw5PsiYCLwBzM7ZB5ji46ra+4q1FjX3FWosa65q1BjHv32uPW6GNncEqnRlm4xd38B2JawDODbgD3nMbbouLrmrkKNdc1dhRrrmrsKNebRb49br4uRzS2RGm3pljmWASSsUDIvsUXH1TV3FWqsa+4q1FjX3FWoMY9+e9x6XYxsbonUaEu3PGBmVwLbAdeZ2UIFxBYdV9fcVaixrrmrUGNdc1ehxjz67XHrdTGyuSVSoy3dshfVWIKwjrmrUGNdc1ehxrrmrkKNefTb49brYmRzS6QT1oiIiIiIlEBHtEVERERESqBGW0RERESkBGq0RURERERKoDNDioiUxMweBZYBZqY2J+7+1DyO+Vl37+ppj81sFeAR4Ep3/0hq+y+Af7j7xC6VJiLSM9Roi4iUa7tuN8VpZjafu79Z4JDvMbP3u/vNBY4pItIX1GiLiIwwM1sMOAH4COFkD2cBR7j7TDNbDfgpsB4wCPwROMDdnzez84CVgMvNbCbwHeB24Bfu/rbU+I8Sj3qb2URgbeBV4GPAwWZ28TD53wH8HFgfeAO4zt13GebhHAd8D9iixeNcAjgPeA/h781NwH7u/kS8fRJwI/BfwLrAn4G9gZMI6/Q6sJO7Pxrj1wBOBjYCpgLfcveLhqlNRKSrNEdbRGTknQ28CbwD2AD4EPDZeNsAcAywPLAmsCIwEcDd9wAeJxwlH+vux2XMtz3wa2Bx4PwO+b8LXA0sQTi98skdxj4NSMxsyxa3jSI08SsT3iC8ApzSFLMrsAewArAacEu8z5LA/wFHAJjZIsA1wAXA0vF+p5nZWh3qExHpGh3RFhEp1yVm1piqMQn4AuFI8uLu/grwkpn9L/B54HR3/wfwjxg/1cxOIDab8+AWd78EwMwWHS4/4Sj2ysDy8cjzjR3GfoVwRPsoYMgUGXefBvymcd3Mvkc4ap12lrs/HG+/ElirMdUmHnn/boz7KPCou58Vr082s98AOwFHZnkSRERGmhptEZFyfTw9R9vM3g2MAZ42s8bmUcCUePsywI+AzYBx8bbn5rGGKanvVx4uP/A1QnN7u5k9B/zQ3c/sMP7PgEPNbLv0RjNbGPhfYGvCEXKAcWY22t0bHxD9d+our7S4PjZV93vM7PnU7fMRpqaIiPQkNdoiIiNrCvAasFSbDyUeTZibvY67P2tmH2fodIvm0/m+BCzcuGJmo4EJTTHp+wyb393/BXwujrUpcK2ZXR+PtLfk7q+b2ZGEBv3+1E1fBQx4j7v/y8zWByYTpsfkNQX4i7tvNRf3FRHpCs3RFhEZQe7+NGEO9A/NbFEzG2Vmq5nZ5jFkHDADeMHMVgAObRri38DbU9cfBBY0s23NbAxwOLDA3OY3s53MrPHByucITfqsDA/tPGBBwtHrhnGEo9LPm9mSzNsUmCsIc8H3MLMx8fIuM1tzHsYUESmVGm0RkZG3JzA/8AChmf01sFy87UhgQ+AF4PfAb5vuewxwuJk9b2aHuPsLwP6E6RtPEo5wPzEP+d8F3GZmM4DLgC+7+z87PaA4FeTbhA8xNpwILAT8B7gVuKrTOMOMP53woc1dgaeAfwHHMsybChGRbhsYHGz+L6SIiIiIiMwrHdEWERERESmBGm0RERERkRKo0RYRERERKYEabRERERGREqjRFhEREREpgRptEREREZESqNEWERERESmBGm0RERERkRKo0RYRERERKcH/B0Be/BQYIai6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12, 4))\n",
    "OrgData.describe(include = 'all').T['count'].plot(kind = 'bar', color = 'Green')\n",
    "plt.xlabel('Features Name')\n",
    "plt.ylabel('exist Count', fontsize = 20)\n",
    "plt.title('Exist data count', fontsize = 20,fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PP8dqNLcgdRX",
    "outputId": "a43bce26-cca1-4446-c8ea-3f3d1f7ee225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40mBy null data we have  36\n",
      "After drop all null data we have  36\n",
      "by null data we have  1  pos instances\n",
      "Without null data we have  1  pos instances\n",
      "dropna null data causes  0  the lose pos instances\n"
     ]
    }
   ],
   "source": [
    "# Data INFO\n",
    "print(Back.BLACK + 'By null data we have ', str(len(OrgData)))\n",
    "print('After drop all null data we have ', str(len(OrgData.dropna())))\n",
    "print('by null data we have ', len(OrgData[OrgData.videos == 1]), ' pos instances')\n",
    "print('Without null data we have ', len(OrgData.dropna()[OrgData.videos == 1]), ' pos instances')\n",
    "print('dropna null data causes ',\n",
    "      len(OrgData[OrgData.videos == 1]) - len(OrgData.dropna()[OrgData.videos == 1])\n",
    "      ,' the lose pos instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I03Axplrg5E4",
    "outputId": "6ea0afb6-3640-4804-dec1-b2ab934aa171"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### feature wth null data list:\n",
    "# null fetures by values\n",
    "OrgData.isnull().sum()[OrgData.isnull().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hbxaB-Y8hBWG"
   },
   "outputs": [],
   "source": [
    "#### First NN Without Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jIKHpJLhVXc",
    "outputId": "20f89d2d-7f54-42e6-8575-0d25dc1d3b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset have  36  Instances\n",
      "dataset have  40    4\n",
      "39    4\n",
      "42    4\n",
      "41    4\n",
      "37    4\n",
      "38    3\n",
      "43    3\n",
      "36    2\n",
      "44    2\n",
      "46    2\n",
      "47    1\n",
      "49    1\n",
      "45    1\n",
      "33    1\n",
      "Name: class1, dtype: int64 class 1  Insctances\n",
      "dataset have  6     10\n",
      "5      7\n",
      "8      6\n",
      "7      3\n",
      "10     3\n",
      "4      2\n",
      "12     1\n",
      "15     1\n",
      "9      1\n",
      "11     1\n",
      "3      1\n",
      "Name: class2, dtype: int64 class 2 Instances\n",
      "dataset have  6    7\n",
      "5    6\n",
      "3    6\n",
      "7    5\n",
      "4    4\n",
      "2    3\n",
      "9    2\n",
      "8    2\n",
      "0    1\n",
      "Name: class3, dtype: int64 class 3 Insctances\n",
      "dataset have  1    11\n",
      "2    10\n",
      "0     8\n",
      "3     4\n",
      "4     3\n",
      "Name: class4, dtype: int64 class 4 Instances\n",
      "dataset have  2    12\n",
      "3    10\n",
      "1     7\n",
      "4     6\n",
      "0     1\n",
      "Name: class5, dtype: int64 class 5 Insctances\n",
      "dataset have  1    13\n",
      "0    11\n",
      "2     6\n",
      "5     3\n",
      "3     2\n",
      "4     1\n",
      "Name: class6, dtype: int64 class 6 Instances\n"
     ]
    }
   ],
   "source": [
    "print('dataset have ',str(len(OrgData)),' Instances')\n",
    "\n",
    "print('dataset have ',str(OrgData.class1.value_counts()),'class 1  Insctances')\n",
    "print('dataset have ',str(OrgData.class2.value_counts()),'class 2 Instances')\n",
    "print('dataset have ',str(OrgData.class3.value_counts()),'class 3 Insctances')\n",
    "print('dataset have ',str(OrgData.class4.value_counts()),'class 4 Instances')\n",
    "print('dataset have ',str(OrgData.class5.value_counts()),'class 5 Insctances')\n",
    "print('dataset have ',str(OrgData.class6.value_counts()),'class 6 Instances')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "6mWz7MzsiraP"
   },
   "outputs": [],
   "source": [
    "# Because of the value count we use class 4 for analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DatPiIAyqddn",
    "outputId": "31d6a033-c55c-4f7f-fc9b-9d954fbb478b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[42mclass4 have \u001b[41m36\u001b[42m instances(rows)\n",
      "\u001b[42mclass4 have \u001b[41m0  \u001b[42m null values\n",
      "\n",
      "\n",
      "\u001b[42mclass4 have \u001b[41m8\u001b[42m 0 value\n",
      "\u001b[42mclass4 have \u001b[41m11\u001b[42m 1 value\n",
      "\u001b[42mclass4 have \u001b[41m10\u001b[42m 2 value\n",
      "\u001b[42mclass4 have \u001b[41m4\u001b[42m 3 value\n",
      "\u001b[42mclass4 have \u001b[41m3\u001b[42m 4 value\n"
     ]
    }
   ],
   "source": [
    "# target feature null count & blacying value\n",
    "class4Count = len(OrgData.class4)\n",
    "class4Null = OrgData.class4.isnull().sum()\n",
    "print(Back.GREEN+f'class4 have '+Back.RED+(str(class4Count))+Back.GREEN+' instances(rows)')\n",
    "print(Back.GREEN+f'class4 have '+Back.RED+(str(class4Null))+'  '+\n",
    "      Back.GREEN+' null values')\n",
    "print('\\n')\n",
    "print(Back.GREEN+f'class4 have '+Back.RED+(str(OrgData.class4.value_counts()[0]))+Back.GREEN+' 0 value')\n",
    "print(Back.GREEN+f'class4 have '+Back.RED+(str(OrgData.class4.value_counts()[1]))+Back.GREEN+' 1 value')\n",
    "print(Back.GREEN+f'class4 have '+Back.RED+(str(OrgData.class4.value_counts()[2]))+Back.GREEN+' 2 value')\n",
    "print(Back.GREEN+f'class4 have '+Back.RED+(str(OrgData.class4.value_counts()[3]))+Back.GREEN+' 3 value')\n",
    "print(Back.GREEN+f'class4 have '+Back.RED+(str(OrgData.class4.value_counts()[4]))+Back.GREEN+' 4 value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "QQ7BYsD7zL1r",
    "outputId": "8c695d6f-eed8-4888-c50e-931ccadd900e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset have \u001b[47m36\u001b[47m instances(rows)\n",
      "dataset have \u001b[47m65   features(columns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b8833e59-1027-456b-b762-c796c3359910\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>videos</th>\n",
       "      <td>36.0</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>10.535654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.75</td>\n",
       "      <td>18.5</td>\n",
       "      <td>27.25</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.876501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.694444</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.983999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.464621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.472708</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>5.027778</td>\n",
       "      <td>2.117763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.401386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class5</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2.361111</td>\n",
       "      <td>1.073120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class6</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>1.478953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8833e59-1027-456b-b762-c796c3359910')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b8833e59-1027-456b-b762-c796c3359910 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b8833e59-1027-456b-b762-c796c3359910');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           count       mean        std  min   25%   50%    75%   max\n",
       "videos      36.0  18.500000  10.535654  1.0  9.75  18.5  27.25  36.0\n",
       "subjects1   36.0   1.444444   0.876501  1.0  1.00   1.0   1.00   4.0\n",
       "subjects2   36.0   1.694444   1.166667  1.0  1.00   1.0   3.00   6.0\n",
       "subjects3   36.0   2.055556   0.983999  1.0  1.00   2.0   2.25   6.0\n",
       "subjects4   36.0   1.111111   0.464621  1.0  1.00   1.0   1.00   3.0\n",
       "...          ...        ...        ...  ...   ...   ...    ...   ...\n",
       "class2      36.0   7.000000   2.472708  3.0  5.00   6.0   8.00  15.0\n",
       "class3      36.0   5.027778   2.117763  0.0  3.00   5.0   6.25   9.0\n",
       "class4      36.0   0.194444   0.401386  0.0  0.00   0.0   0.00   1.0\n",
       "class5      36.0   2.361111   1.073120  0.0  2.00   2.0   3.00   4.0\n",
       "class6      36.0   1.388889   1.478953  0.0  0.00   1.0   2.00   5.0\n",
       "\n",
       "[65 rows x 8 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define x, y \n",
    "x = OrgData.drop('class4', axis = 1)\n",
    "y = OrgData.class4\n",
    "\n",
    "\"\"\"\n",
    "changing y to (0,1,2 :0)\n",
    "and \n",
    "(3,4: 1) \n",
    "for a balance clasification\n",
    "\"\"\"\n",
    "# We ave 0, 1; 0:low risk, 1: High risk\n",
    "y[y == 0] = 0\n",
    "y[y == 1] = 0\n",
    "y[y == 2] = 0\n",
    "\n",
    "y[y == 3] = 1\n",
    "y[y == 4] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "id": "-j6kPEyMnJ1M",
    "outputId": "a09583cc-1c6a-4a78-e34f-a0be30e7859f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset have 36 instances(rows)\n",
      "dataset have 65   features(columns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1d32e471-22d1-43fd-9790-2dfd421cc5fe\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>videos</th>\n",
       "      <td>36.0</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>10.535654</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.75</td>\n",
       "      <td>18.5</td>\n",
       "      <td>27.25</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects1</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.444444</td>\n",
       "      <td>0.876501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.694444</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>0.983999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjects4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>0.464621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class2</th>\n",
       "      <td>36.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.472708</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>5.027778</td>\n",
       "      <td>2.117763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class4</th>\n",
       "      <td>36.0</td>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.401386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class5</th>\n",
       "      <td>36.0</td>\n",
       "      <td>2.361111</td>\n",
       "      <td>1.073120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class6</th>\n",
       "      <td>36.0</td>\n",
       "      <td>1.388889</td>\n",
       "      <td>1.478953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 8 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d32e471-22d1-43fd-9790-2dfd421cc5fe')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1d32e471-22d1-43fd-9790-2dfd421cc5fe button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1d32e471-22d1-43fd-9790-2dfd421cc5fe');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           count       mean        std  min   25%   50%    75%   max\n",
       "videos      36.0  18.500000  10.535654  1.0  9.75  18.5  27.25  36.0\n",
       "subjects1   36.0   1.444444   0.876501  1.0  1.00   1.0   1.00   4.0\n",
       "subjects2   36.0   1.694444   1.166667  1.0  1.00   1.0   3.00   6.0\n",
       "subjects3   36.0   2.055556   0.983999  1.0  1.00   2.0   2.25   6.0\n",
       "subjects4   36.0   1.111111   0.464621  1.0  1.00   1.0   1.00   3.0\n",
       "...          ...        ...        ...  ...   ...   ...    ...   ...\n",
       "class2      36.0   7.000000   2.472708  3.0  5.00   6.0   8.00  15.0\n",
       "class3      36.0   5.027778   2.117763  0.0  3.00   5.0   6.25   9.0\n",
       "class4      36.0   0.194444   0.401386  0.0  0.00   0.0   0.00   1.0\n",
       "class5      36.0   2.361111   1.073120  0.0  2.00   2.0   3.00   4.0\n",
       "class6      36.0   1.388889   1.478953  0.0  0.00   1.0   2.00   5.0\n",
       "\n",
       "[65 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row and column count\n",
    "rowCount = OrgData.shape[0]\n",
    "colCount = OrgData.shape[1]\n",
    "print(f'dataset have '+(str(rowCount))+' instances(rows)')\n",
    "print(f'dataset have '+(str(colCount))+'  '+\n",
    "      ' features(columns)')\n",
    "\n",
    "OrgData.describe(include = 'all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3h5jAuynTCD",
    "outputId": "a2f95f01-c7e2-4109-d35a-e5b2c07debca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "13    1\n",
       "14    0\n",
       "15    0\n",
       "16    0\n",
       "17    0\n",
       "18    1\n",
       "19    0\n",
       "20    0\n",
       "21    1\n",
       "22    0\n",
       "23    1\n",
       "24    0\n",
       "25    0\n",
       "26    0\n",
       "27    0\n",
       "28    1\n",
       "29    0\n",
       "30    1\n",
       "31    0\n",
       "32    1\n",
       "33    0\n",
       "34    0\n",
       "35    0\n",
       "Name: class4, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrgData.class4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2YK-gO5sscx9",
    "outputId": "cb20bef6-3b99-4afc-d7a3-8095b0e926cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[40mPercentage of trainig data is :  \u001b[41m77  %\n",
      "\u001b[40mPercentage of trainig data is :  \u001b[41m22  %\n",
      "\u001b[40mtraining data Neg instances count is :  24  & pos counts :  4\n",
      "Pos/Neg in trainig data is :  0.16666666666666666\n",
      "\u001b[41mtest data Neg instances count is :  5  & pos counts :  3\n",
      "Pos/Neg in trainig data is :  0.6\n"
     ]
    }
   ],
   "source": [
    "# Seperate test and train data\n",
    "# use stratified method for split input and output into train and test parts: \n",
    "#trainData is Imbalanced and test data in fixed for all tests\n",
    "np.random.seed(42)\n",
    "trainData, testData = train_test_split(OrgData, \n",
    "                                       test_size = .2)\n",
    "\n",
    "# percentage of trainig and test \n",
    "print(Back.BLACK + 'Percentage of trainig data is : ',Back.RED + \n",
    "      str(int(((len(trainData)/len(OrgData))*100))), ' %')\n",
    "print(Back.BLACK + 'Percentage of trainig data is : ',Back.RED + \n",
    "      str(int(((len(testData)/len(OrgData))*100))), ' %')\n",
    "\n",
    "# count of pos and neg of trainig and test parts\n",
    "print(Back.BLACK + 'training data Neg instances count is : ', trainData.class4.value_counts()[0], \n",
    "     ' & pos counts : ',trainData.class4.value_counts()[1] )\n",
    "print('Pos/Neg in trainig data is : ',trainData.class4.value_counts()[1]/trainData.class4.value_counts()[0] )\n",
    "print(Back.RED + 'test data Neg instances count is : ', testData.class4.value_counts()[0], \n",
    "     ' & pos counts : ', testData.class4.value_counts()[1] )\n",
    "print('Pos/Neg in trainig data is : ',testData.class4.value_counts()[1]/testData.class4.value_counts()[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "kV3KNu_91VsT"
   },
   "outputs": [],
   "source": [
    "# Data is imbalance now \n",
    "## We should balance it with balancer method\n",
    "## ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# For balancing data in this part, SSO will be implemented\n",
    "# -------------------------------------------------------------------------------------------------------\n",
    "# Oversample trainig data with SSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ja7Zlmz21r8X",
    "outputId": "fab3df38-b49f-48cb-8173-bb39ddd74ad5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-20 15:42:16,052:INFO:SSO: Running sampling via ('SSO', \"{'proportion': 1.0, 'n_neighbors': 5, 'nn_params': {}, 'h': 10, 'n_iter': 5, 'n_jobs': 1, 'random_state': None, 'class_name': 'SSO'}\")\n",
      "INFO:smote_variants:SSO: Running sampling via ('SSO', \"{'proportion': 1.0, 'n_neighbors': 5, 'nn_params': {}, 'h': 10, 'n_iter': 5, 'n_jobs': 1, 'random_state': None, 'class_name': 'SSO'}\")\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "2023-03-20 15:42:16,350:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2023-03-20 15:42:16,360:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "2023-03-20 15:42:16,440:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2023-03-20 15:42:16,444:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "2023-03-20 15:42:16,742:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2023-03-20 15:42:16,750:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "2023-03-20 15:42:16,807:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2023-03-20 15:42:16,812:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "2023-03-20 15:42:17,032:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2023-03-20 15:42:17,040:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "2023-03-20 15:42:17,055:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2023-03-20 15:42:17,064:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "2023-03-20 15:42:17,162:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2023-03-20 15:42:17,169:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "2023-03-20 15:42:17,183:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2023-03-20 15:42:17,187:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "2023-03-20 15:42:17,291:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2023-03-20 15:42:17,298:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "2023-03-20 15:42:17,308:INFO:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: NN fitting with metric minkowski\n",
      "2023-03-20 15:42:17,314:INFO:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n",
      "INFO:smote_variants:NearestNeighborsWithMetricTensor: kneighbors query minkowski\n"
     ]
    }
   ],
   "source": [
    "# define input & output\n",
    "x = OrgData.drop('class4', axis = 1)\n",
    "y = OrgData.class4\n",
    "\n",
    "# call input ad output as array for function\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "# call SSO here for oversampling\n",
    "oversampler= sv.SSO()\n",
    "x_sampSSO, y_sampSSO= oversampler.sample(x, y)\n",
    "\n",
    "ssotrain_x = x_sampSSO\n",
    "ssotrain_y = y_sampSSO\n",
    "# filtering new samples\n",
    "x_sampSSO, y_sampSSO= x_sampSSO[len(x):], y_sampSSO[len(y):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O04ZiWnZsgLO",
    "outputId": "0c414f5d-52a6-40dd-9629-75e7328506af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 13ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.9712 - accuracy: 0.4773\n",
      "1/1 [==============================] - 0s 162ms/step - loss: 7.6246 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7.624619007110596, 0.5]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create NN for unbalanced dataset, first a simple NN\n",
    "\n",
    "# define seed \n",
    "tf.random.set_seed(42)\n",
    "ssotrain_x, x_test, ssotrain_y, y_test = train_test_split(ssotrain_x, ssotrain_y,\n",
    "                                       test_size = .2)\n",
    "# Create a model \n",
    "unbalanced_model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Complie the model\n",
    "unbalanced_model_1.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                          optimizer = tf.keras.optimizers.SGD(),\n",
    "                          metrics = ['accuracy'])\n",
    "\n",
    "# fit the models here\n",
    "history_unbalanced_1 = unbalanced_model_1.fit(ssotrain_x, ssotrain_y, epochs = 100)\n",
    "unbalanced_model_1.evaluate(x_test, y_test) # end line of results --loss & accuracy on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IVfBPKJsqsm",
    "outputId": "d8e42225-8071-4557-f62c-fda5f93ce62f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65\n",
      "Trainable params: 65\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the model summary \n",
    "unbalanced_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80j-PsUFstBE",
    "outputId": "8916f58d-1a88-4a15-9c8e-cc225c461753"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 17ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.4068 - accuracy: 0.5143\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 10.1662 - accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.166158676147461, 0.3333333432674408]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define seed \n",
    "tf.random.set_seed(42)\n",
    "ssotrain_x, x_test, ssotrain_y, y_test = train_test_split(ssotrain_x, ssotrain_y,\n",
    "                                       test_size = .2)\n",
    "# Create a model \n",
    "SSO_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Complie the model\n",
    "SSO_model_2.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                          optimizer = tf.keras.optimizers.SGD(),\n",
    "                          metrics = ['accuracy'])\n",
    "\n",
    "# fit the models here\n",
    "history_unbalanced_2 = SSO_model_2.fit(ssotrain_x, ssotrain_y, epochs = 100)\n",
    "SSO_model_2.evaluate(x_test, y_test) # end line of results --loss & accuracy on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Knp2qgcXs1ZU",
    "outputId": "087888bb-4389-4019-adcb-113199710a67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the model summary \n",
    "SSO_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4oUKvSGs3ZS",
    "outputId": "103388d7-f166-406c-b9cc-3968aa5b2bb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 8.1692 - accuracy: 0.4643\n",
      "1/1 [==============================] - 0s 140ms/step - loss: 4.3569 - accuracy: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.356925010681152, 0.7142857313156128]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define seed \n",
    "tf.random.set_seed(42)\n",
    "ssotrain_x, x_test, ssotrain_y, y_test = train_test_split(ssotrain_x, ssotrain_y,\n",
    "                                       test_size = .2)\n",
    "\n",
    "# Create a model \n",
    "SSo_model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(12, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(8, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'relu')\n",
    "    \n",
    "])\n",
    "\n",
    "# Complie the model\n",
    "SSo_model_3.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                          optimizer = tf.keras.optimizers.SGD(),\n",
    "                          metrics = ['accuracy'])\n",
    "\n",
    "# fit the models here\n",
    "history_unbalanced_3 = SSo_model_3.fit(ssotrain_x, ssotrain_y, epochs = 100)\n",
    "SSo_model_3.evaluate(x_test, y_test) # end line of results --loss & accuracy on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BY1GM9gis-5R",
    "outputId": "6934c34a-c534-4089-c615-c1db4b9724b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 893\n",
      "Trainable params: 893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the model summary \n",
    "SSo_model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vpm5qJtdtAcx",
    "outputId": "3a5e98c2-3e49-4d01-9019-d89976c7ace2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 5.1416 - accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.1416497230529785, 0.6666666865348816]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define seed \n",
    "tf.random.set_seed(42)\n",
    "ssotrain_x, x_test, ssotrain_y, y_test = train_test_split(ssotrain_x, ssotrain_y,\n",
    "                                       test_size = .2)\n",
    "\n",
    "# Create a model \n",
    "SSO_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(12, activation = 'selu'),\n",
    "    tf.keras.layers.Dense(8, activation = 'selu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'selu')\n",
    "    \n",
    "])\n",
    "\n",
    "# Complie the model\n",
    "SSO_model_4.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                          optimizer = tf.keras.optimizers.Adam(), # change Optimizer to Adam by default Learning Rate\n",
    "                          metrics = ['accuracy'])\n",
    "\n",
    "# fit the models here\n",
    "history_unbalanced_4 = SSO_model_4.fit(ssotrain_x, ssotrain_y, epochs = 100)\n",
    "SSO_model_4.evaluate(x_test, y_test) # end line of results --loss & accuracy on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IiqqyLUtI4T",
    "outputId": "2dec1d29-3f6e-416b-c2ad-0ef0053c79d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 893\n",
      "Trainable params: 893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the model summary \n",
    "SSO_model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wNG4lHvutLTA",
    "outputId": "ba90ee15-ab58-4c8a-ef30-09e6294a6f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1.0220 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.9445 - accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.8744 - accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.8132 - accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.7561 - accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.7003 - accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6612 - accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6442 - accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6425 - accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.6389 - accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6369 - accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.6296 - accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.6153 - accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5949 - accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5711 - accuracy: 0.5455\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5484 - accuracy: 0.5455\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.5263 - accuracy: 0.6364\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5060 - accuracy: 0.7273\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4903 - accuracy: 0.7727\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4811 - accuracy: 0.7727\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.4729 - accuracy: 0.7727\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4647 - accuracy: 0.8182\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4551 - accuracy: 0.8636\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.4439 - accuracy: 0.9091\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4316 - accuracy: 0.9091\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4187 - accuracy: 0.9091\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.4068 - accuracy: 0.9545\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3961 - accuracy: 0.9545\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.3887 - accuracy: 0.9545\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3838 - accuracy: 0.9545\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3791 - accuracy: 0.9545\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3742 - accuracy: 0.9545\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3693 - accuracy: 0.9545\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3638 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3578 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3518 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3468 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3426 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3382 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3335 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3290 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3250 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.3211 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3177 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3144 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3112 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.3079 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.3044 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3007 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2970 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2931 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2893 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2854 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2818 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2785 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2759 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2731 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2697 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2662 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.2634 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.2605 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2576 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2548 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2519 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2490 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2460 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2428 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2397 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2365 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2334 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2304 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2278 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.2250 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2224 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2198 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2173 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2147 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2120 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.2092 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2065 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2038 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.2014 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1990 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1965 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1941 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1920 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1897 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1873 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1848 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1829 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1806 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1783 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1762 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1741 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1718 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1697 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1676 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1654 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1634 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1613 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff1f2e13c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 202ms/step - loss: 0.1996 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19961096346378326, 1.0]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define seed \n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model \n",
    "SSO5 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(12, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(8, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'sigmoid') # change into sigmoid\n",
    "    \n",
    "])\n",
    "\n",
    "# Complie the model\n",
    "SSO5.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                          optimizer = tf.keras.optimizers.Adam(), # change Optimizer to Adam by default Learning Rate\n",
    "                          metrics = ['accuracy'])\n",
    "\n",
    "# fit the models here\n",
    "history_unbalanced_5 = SSO5.fit(ssotrain_x, ssotrain_y, epochs = 100)\n",
    "SSO5.evaluate(x_test, y_test) # end line of results --loss & accuracy on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNy8qmfntS7F",
    "outputId": "071bbbc3-4620-421b-ebf7-305f78d0ca4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 12)                780       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 893\n",
      "Trainable params: 893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the model summary \n",
    "SSO5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LS3fnCg8tUat",
    "outputId": "211d6aab-e439-4a8f-c733-294684641f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 850ms/step - loss: 7.0374 - accuracy: 0.5000\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0144 - accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.0085 - accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.0056 - accuracy: 0.5000\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0023 - accuracy: 0.5000\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 6.5647 - accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 6.4173 - accuracy: 0.5455\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 5.3015 - accuracy: 0.5455\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 4.7514 - accuracy: 0.5455\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 4.6083 - accuracy: 0.5455\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 4.0518 - accuracy: 0.4545\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.9459 - accuracy: 0.4091\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 2.2468 - accuracy: 0.4545\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1510 - accuracy: 0.4545\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1311 - accuracy: 0.4545\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.6030 - accuracy: 0.5000\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5996 - accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.6537 - accuracy: 0.4545\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 2.1756 - accuracy: 0.4091\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1741 - accuracy: 0.4091\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1652 - accuracy: 0.4091\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1512 - accuracy: 0.4091\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.1315 - accuracy: 0.4091\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.6714 - accuracy: 0.4091\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4952 - accuracy: 0.4091\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.4282 - accuracy: 0.5455\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3789 - accuracy: 0.5909\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.3399 - accuracy: 0.6364\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.3086 - accuracy: 0.6364\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.2845 - accuracy: 0.6364\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2677 - accuracy: 0.6364\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2546 - accuracy: 0.6364\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2434 - accuracy: 0.6818\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2332 - accuracy: 0.7273\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2272 - accuracy: 0.5909\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2221 - accuracy: 0.5909\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.2158 - accuracy: 0.5909\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2079 - accuracy: 0.6364\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2003 - accuracy: 0.6818\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1927 - accuracy: 0.6818\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1848 - accuracy: 0.6818\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1778 - accuracy: 0.7273\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.1687 - accuracy: 0.7273\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.1587 - accuracy: 0.7727\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1494 - accuracy: 0.8636\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1421 - accuracy: 0.8636\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1347 - accuracy: 0.9091\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1268 - accuracy: 0.9091\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1188 - accuracy: 0.9091\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1107 - accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7ff1f2c28280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 156ms/step - loss: 2.6740 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.674021005630493, 0.8333333134651184]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define seed \n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# multiple perceptron with CNN Activation (3 relu)\n",
    "\n",
    "# Create a model \n",
    "SSO6 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(20, activation = 'relu'), # Back to 20 like CNN Backpropagation\n",
    "    tf.keras.layers.Dense(1, activation = 'relu') # Create 1 dense for multiple perceptron creation\n",
    "    \n",
    "])\n",
    "\n",
    "# Complie the model\n",
    "SSO6.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                          optimizer = tf.keras.optimizers.Adam(), \n",
    "                          metrics = ['accuracy'])\n",
    "\n",
    "# fit the models here\n",
    "history_unbalanced_6 = SSO6.fit(ssotrain_x, ssotrain_y, epochs = 50)\n",
    "SSO6.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BTvLMoVBtly-",
    "outputId": "322227c9-29a6-4c1d-c17a-3524ab8e770d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 20)                1300      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,741\n",
      "Trainable params: 1,741\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# the model summary \n",
    "SSO6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "lPiXb3ettWbn"
   },
   "outputs": [],
   "source": [
    "#### find the best Learnig Rate for work -- work on end model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2obn6UHetbY9",
    "outputId": "fb5ef76f-d6b1-4396-b5b8-a68bf124a6d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 7.7277 - accuracy: 0.5000 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7224 - accuracy: 0.5000 - lr: 1.1220e-04\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7170 - accuracy: 0.5000 - lr: 1.2589e-04\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 1.4125e-04\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 1.5849e-04\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 1.7783e-04\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 1.9953e-04\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 2.2387e-04\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 2.5119e-04\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 2.8184e-04\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 3.1623e-04\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 3.5481e-04\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 3.9811e-04\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 4.4668e-04\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 5.0119e-04\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 5.6234e-04\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 6.3096e-04\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 7.0795e-04\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 7.9433e-04\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 8.9125e-04\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0011\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0013\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0014\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0016\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0018\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0020\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0022\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0028\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0032\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0035\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0040\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0045\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0050\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0056\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0063\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0071\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0079\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0089\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0100\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0112\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0126\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0141\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0158\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0178\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0200\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0224\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0251\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000 - lr: 0.0282\n",
      "1/1 [==============================] - 0s 160ms/step - loss: 5.1416 - accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.1416497230529785, 0.6666666865348816]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define seed \n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model \n",
    "SSO7 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(20, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'relu') # sigmoid not good, change to relu\n",
    "    \n",
    "])\n",
    "\n",
    "# Complie the model\n",
    "SSO7.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                          optimizer = tf.keras.optimizers.Adam(), # change Optimizer to Adam by default Learning Rate\n",
    "                          metrics = ['accuracy'])\n",
    "\n",
    "# Create learning rate callback\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch : 1e-4 * 10 **(epoch / 20))\n",
    "\n",
    "# fit the models here\n",
    "history_unbalanced_6 = SSO7.fit(ssotrain_x, ssotrain_y, epochs = 50, callbacks = [lr_scheduler])\n",
    "SSO7.evaluate(x_test, y_test) # end line of results --loss & accuracy on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "7FDHKEostf6E"
   },
   "outputs": [],
   "source": [
    "### the best LR in this plot is a little bigger then 10 ** -4 -- use this value of lr on end model and its better result of unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sIcI-2TWtjbx",
    "outputId": "b7078643-2be9-484a-cf7a-4db5ff05a049"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 2/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 3/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 4/35\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 5/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 6/35\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 7/35\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 8/35\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 9/35\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 10/35\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 11/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 12/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 13/35\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 14/35\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 15/35\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 16/35\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 17/35\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 18/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 19/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 20/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 21/35\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 22/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 23/35\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 24/35\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 25/35\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 26/35\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 27/35\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 28/35\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 29/35\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 30/35\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 31/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 32/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 33/35\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 34/35\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "Epoch 35/35\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.7125 - accuracy: 0.5000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 5.1416 - accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.1416497230529785, 0.6666666865348816]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define seed \n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Create a model \n",
    "SSO8 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(20, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(10, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation = 'relu') # sigmoid not good, change to relu\n",
    "    \n",
    "])\n",
    "\n",
    "# Complie the model\n",
    "SSO8.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                          optimizer = tf.keras.optimizers.Adam(lr = 0.0002), # change Optimizer to Adam by default Learning Rate\n",
    "                          metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "# fit the models here\n",
    "history_unbalanced_6 = SSO8.fit(ssotrain_x, ssotrain_y, epochs = 35)\n",
    "SSO8.evaluate(x_test, y_test) # end line of results --loss & accuracy on test"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
